# MMDetection - APIs

Official GitHub: https://github.com/open-mmlab/mmdetection

- Model zoo: https://mmdetection.readthedocs.io/en/latest/model_zoo.html

Official Documentation: https://mmdetection.readthedocs.io/en/latest/

## Basic features

### Inference with existing models

#### Files

|        | Config File                                   | Checkpoint File                                   |
| ------ | --------------------------------------------- | ------------------------------------------------- |
| Path   | `configs/<model_name>/<backbone_and_dataset>` | download through `configs/<model_name>/README.md` |
| Format | In *Configs* section                          | Saved via PyTorch                                 |

#### Functions

| Function name        | Function usage                                               |
| -------------------- | ------------------------------------------------------------ |
| `init_detector`      | Initialize a model with a configs file and a checkpoint file |
| `inference_detector` | Single-image-inference with a built model                    |

#### Other features

- `async` support: Allows not to block CPU on GPU bound inference code and enables better CPU/GPU utilization for single-threaded application. Inference can be done concurrently either between different input samples or between different models of pipelines.

#### Demo code

`demo/image_demo.py`

### Test existing models on standard datasets

#### Dataset

Put dataset in path: `data/<dataset_name>`

COCO dataset: 

```
mmdetection
├── data
│   ├── coco
│   │   ├── annotations
│   │   ├── train2017
│   │   ├── val2017
│   │   ├── test2017
```

#### Test scripts

```powershell
# single-gpu testing
python tools/test.py \
    ${CONFIG_FILE} \
    ${CHECKPOINT_FILE} \
    [--out ${RESULT_FILE}] \
    [--eval ${EVAL_METRICS}] \
    [--show]

# multi-gpu testing
bash tools/dist_test.sh \
    ${CONFIG_FILE} \
    ${CHECKPOINT_FILE} \
    ${GPU_NUM} \
    [--out ${RESULT_FILE}] \
    [--eval ${EVAL_METRICS}]
```

Arguments:

- `RESULT_FILE`: Filename of output in pickle format.
- `EVAL_METRICS`: Evaluation metrics, different for different datasets
  - COCO: `bbox`, `segm`, `proposal`, note that no `mAP` supported for COCO here!
  - PASCAL VOC: `mAP`, `recall`
- `--show-dir`: If specified, detection results will be plotted on the images and saved to the specified directory, only applicable to single GPU testing and used for debugging and visualization. Do NOT need a GUI available for using this option.
- Batch inference: `--cfg-options data.test.samples_per_gpu=<images_per_batch>`

### Train predefined models on standard datasets

Train directly with `configs` file, no checkpoints used here.

```powershell
# single-gpu training
python tools/train.py \
    ${CONFIG_FILE} \
    [optional arguments]
    
# multi-gpu-training
bash ./tools/dist_train.sh \
    ${CONFIG_FILE} \
    ${GPU_NUM} \
    [optional arguments]
```

To launch multiple jobs simultaneously, set the port (29500 by default) in commands.

```powershell
CUDA_VISIBLE_DEVICES=0,1,2,3 PORT=29500 ./tools/dist_train.sh ${CONFIG_FILE} 4
CUDA_VISIBLE_DEVICES=4,5,6,7 PORT=29501 ./tools/dist_train.sh ${CONFIG_FILE} 4
```

#### TODO: Manage jobs with Slurm

## DIY the process

### Configs

To inspect the config file, run `python tools/misc/print_config.py /PATH/TO/CONFIG` to see the complete config.

#### Config file structure

- Base components: 4 basic component types under `config/_base_`, dataset, model, schedule, default_runtime.
- *Primitive* config: configs composed by components from `_base_`.
- Inherit: To modify on existing methods, inherit the model config by specifying `_base_ = ../<model_group>/<model_confif_file>`, note that the **maximum of inheritance level is 3**
- For all configs under the same folder, it is recommended to have only **one** *primitive* config.
- Build an entirely new method that does not share the structure with any of the existing methods, create a folder under `configs/`.

#### Config name style

`{model}_[model setting]_{backbone}_{neck}_[norm setting]_[misc]_[gpu x batch_per_gpu]_{schedule}_{dataset}`

- `[gpu x batch_per_gpu]`: GPUs and samples per GPU, `8x2` is used by default.
- `{schedule}`: training schedule, options are `1x`, `2x`, `20e`, etc. `1x` and `2x` means 12 epochs and 24 epochs respectively. `20e` is adopted in cascade models, which denotes 20 epochs. 
  - For `1x`/`2x`, initial learning rate decays by a factor of 10 at the 8/16th and 11/22th epochs. For `20e`, initial learning rate decays by a factor of 10 at the 16th and 19th epochs.

#### Config file style

```python
model = dict(
    backbone,
    neck,
    rpn_head,
    roi_head,
    train_cfg,
    test_cfg,
	...
)
dataset_type = ...
data_root = ...
train_pipeline = [...]		# intermediate variable
test_pipeline = [...]		# intermediate variable
data = dict(
    ...
)
evaluation = ...
optimizer = ...
```

#### Modify config through script arguments

Specify `--cfg-options` when submitting jobs using `train.py` or `test.py`.

- Update config keys of dict chains.

  The config options can be specified following the order of the dict keys in the original config. For example, `--cfg-options model.backbone.norm_eval=False`.

- Update keys inside a list of configs.

  For example, the training pipeline `data.train.pipeline` is normally a list e.g. `[dict(type='LoadImageFromFile'), ...]`. Specify `--cfg-options data.train.pipeline.0.type=LoadImageFromWebcam` to update.

- Update values of list/tuples.

  For example, the config file normally sets `workflow=[('train', 1)]`. Specify `--cfg-options workflow="[(train,1),(val,1)]"` to update. 

  Quotation mark “ is necessary, and that **NO** white space is allowed inside the quotation marks.

### Customize datasets

Recommendation: convert the data into COCO formats and do the conversion offline. For example, use a dataset with 5 categories in COCO format.

1. Modify the config file for using customized dataset.

   In config file, explicitly add the `classes` fields in  `data.train`, `data.val` and `data.test`.

   ```python
   # 1. dataset settings
   dataset_type = 'CocoDataset'
   classes = ('a', 'b', 'c', 'd', 'e')
   data = dict(
       samples_per_gpu=2,
       workers_per_gpu=2,
       train=dict(
           type=dataset_type,
           # explicitly add your class names to the field `classes`
           classes=classes,
           ann_file='path/to/your/train/annotation_data',
           img_prefix='path/to/your/train/image_data'),
       val=dict(
           type=dataset_type,
           # explicitly add your class names to the field `classes`
           classes=classes,
           ann_file='path/to/your/val/annotation_data',
           img_prefix='path/to/your/val/image_data'),
       test=dict(
           type=dataset_type,
           # explicitly add your class names to the field `classes`
           classes=classes,
           ann_file='path/to/your/test/annotation_data',
           img_prefix='path/to/your/test/image_data'))
   ```

   Specify the `num_classes` filed in the `model` part, explicitly over-write all the `num_classes` from default value.

   ```python
   # 2. model settings
   
   # explicitly over-write all the `num_classes` field from default 80 to 5.
   model = dict(
       roi_head=dict(
           bbox_head=[
               dict(
                   type='Shared2FCBBoxHead',
                   # explicitly over-write all the `num_classes` field from default 80 to 5.
                   num_classes=5),
               dict(
                   type='Shared2FCBBoxHead',
                   # explicitly over-write all the `num_classes` field from default 80 to 5.
                   num_classes=5),
               dict(
                   type='Shared2FCBBoxHead',
                   # explicitly over-write all the `num_classes` field from default 80 to 5.
                   num_classes=5)],
       # explicitly over-write all the `num_classes` field from default 80 to 5.
       mask_head=dict(num_classes=5)))
   ```

2. Check the organization of customize dataset.

### Customize data pipelines

Data pipelines: specify the process that an image goes through before training or testing. 

- Data loading: `LoadImageFromFile`, `LoadAnnotations`, `LoadProposals`
- Pre-processing: `Resize`, `RandomFlip`, `Pad`, `RandomCrop`, `Normalize`, `SegRescale`, `PhotoMetricDistortion`, `Expand`, `MinIoURandomCrop`, `Corrupt`
- Formatting: `ToTensor`, `ImageToTensor`, `Transpose`, `ToDataContainer`, `DefaultFormatBundle`, `Collect`
- Test time augmentation: `MultiScaleFlipAug`

### Customize models

We basically categorize model components into 5 types.

- backbone: usually an FCN network to extract feature maps, e.g., ResNet, MobileNet.
- neck: the component between backbones and heads, e.g., FPN, PAFPN.
- head: the component for specific tasks, e.g., bbox prediction and mask prediction.
- roi extractor: the part for extracting RoI features from feature maps, e.g., RoI Align.
- loss: the component in head for calculating losses, e.g., FocalLoss, L1Loss, and GHMLoss.

To develop a new component, create a new file in `mmdet/models/<component>/<component_file>`, treat the component as a class inherited from `nn.Module`. Also, don't forget to add `@<COMPONENT>.register_module()` before class definition!

To import the new component, add `from .<component_file> import <component_class_name>` line to `mmdet/models/<component>/__init__.py`. 

Or alternatively, add

```python
custom_imports = dict(
    imports=['mmdet.models.<component>.<component_file>'],
    allow_failed_imports=False)
```

to the config file to avoid modifying the original code.

### Customize runtime settings

#### Optimizer

Already support to use all the optimizers implemented by PyTorch. 

To customize self-implemented optimizer, create a new directory named `mmdet/core/optimizer`. And then implement the new optimizer in a file `mmdet/core/optimizer/<cus_optimizer>`.

The import and usage of self-implemented optimizer is just like self-implemented components.

#### TODO: Training schedule

#### TODO: Workflow

#### TODO: Hooks

### Customize Losses

TODO

This section is about tweaking loss and weighting loss (element-wisely). Not implementing a new kind of loss, which can be treated as a component.

### Finetuning models

Use models provided in the Model Zoo for other datasets to obtain better performance.

Two steps:

- Add support for the new dataset following Customize Datasets.
- Modify the configs as follows:
  - Inherit base configs: Specify `_base_= [...]` in configs.
  - Modify head: By only changing `num_classes` in the roi_head, the weights of the pre-trained models are mostly reused except the final prediction head.
  - Modify dataset.
  - Modify training schedule: Usually requires smaller learning rate and less training epochs.
  - Use pre-trained model: The new config add the link of pre-trained models in the `load_from`.

