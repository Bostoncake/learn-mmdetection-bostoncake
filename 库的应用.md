# MMDetection - APIs

Official GitHub: https://github.com/open-mmlab/mmdetection

- Model zoo: https://mmdetection.readthedocs.io/en/latest/model_zoo.html

Official Documentation: https://mmdetection.readthedocs.io/en/latest/

## Basic features

### Inference with existing models

#### Files

|        | Config File                                   | Checkpoint File                                   |
| ------ | --------------------------------------------- | ------------------------------------------------- |
| Path   | `configs/<model_name>/<backbone_and_dataset>` | download through `configs/<model_name>/README.md` |
| Format | In *Configs* section                          | Saved via PyTorch                                 |

#### Functions

| Function name        | Function usage                                               |
| -------------------- | ------------------------------------------------------------ |
| `init_detector`      | Initialize a model with a configs file and a checkpoint file |
| `inference_detector` | Single-image-inference with a built model                    |

#### Other features

- `async` support: Allows not to block CPU on GPU bound inference code and enables better CPU/GPU utilization for single-threaded application. Inference can be done concurrently either between different input samples or between different models of pipelines.

#### Demo code

`demo/image_demo.py`

### Test existing models on standard datasets

#### Dataset

Put dataset in path: `data/<dataset_name>`

COCO dataset: 

```
mmdetection
├── data
│   ├── coco
│   │   ├── annotations
│   │   ├── train2017
│   │   ├── val2017
│   │   ├── test2017
```

#### Test scripts

```powershell
# single-gpu testing
python tools/test.py \
    ${CONFIG_FILE} \
    ${CHECKPOINT_FILE} \
    [--out ${RESULT_FILE}] \
    [--eval ${EVAL_METRICS}] \
    [--show]

# multi-gpu testing
bash tools/dist_test.sh \
    ${CONFIG_FILE} \
    ${CHECKPOINT_FILE} \
    ${GPU_NUM} \
    [--out ${RESULT_FILE}] \
    [--eval ${EVAL_METRICS}]
```

Arguments:

- `RESULT_FILE`: Filename of output in pickle format.
- `EVAL_METRICS`: Evaluation metrics, different for different datasets
  - COCO: `bbox`, `segm`, `proposal`, note that no `mAP` supported for COCO here!
  - PASCAL VOC: `mAP`, `recall`
- `--show-dir`: If specified, detection results will be plotted on the images and saved to the specified directory, only applicable to single GPU testing and used for debugging and visualization. Do NOT need a GUI available for using this option.
- Batch inference: `--cfg-options data.test.samples_per_gpu=<images_per_batch>`

### Train predefined models on standard datasets

Train directly with `configs` file, no checkpoints used here.

```powershell
# single-gpu training
python tools/train.py \
    ${CONFIG_FILE} \
    [optional arguments]
    
# multi-gpu-training
bash ./tools/dist_train.sh \
    ${CONFIG_FILE} \
    ${GPU_NUM} \
    [optional arguments]
```

To launch multiple jobs simultaneously, set the port (29500 by default) in commands.

```powershell
CUDA_VISIBLE_DEVICES=0,1,2,3 PORT=29500 ./tools/dist_train.sh ${CONFIG_FILE} 4
CUDA_VISIBLE_DEVICES=4,5,6,7 PORT=29501 ./tools/dist_train.sh ${CONFIG_FILE} 4
```

#### TODO: Manage jobs with Slurm

## DIY the process

### Configs

To inspect the config file, run `python tools/misc/print_config.py /PATH/TO/CONFIG` to see the complete config.

#### Modify config through script arguments



#### Change 



### Customize datasets



### Customize models



### Customize runtime settings



### Customize Losses



### Finetuning models



### TODO: Customize data pipelines